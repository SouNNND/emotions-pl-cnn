{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>VGG Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG11(nn.Module):\n",
    "    def __init__(self, num_classes=7):  # Adjust the number of classes for FER+\n",
    "        super(VGG11, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, padding=1),  # Change 1 to 3 for RGB\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>FER Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class FERPlusDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None, train=True):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        if(train):\n",
    "            self.data = self.data[self.data['Usage'] != 'PrivateTest']\n",
    "        else:\n",
    "            self.data = self.data[self.data['Usage'] == 'PrivateTest']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.fromstring(self.data.loc[idx, 'pixels'], dtype=int, sep=' ').reshape(48, 48)\n",
    "        image = Image.fromarray(image.astype(np.uint8))\n",
    "\n",
    "        label = self.data.loc[idx, 'emotion']\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations for FER+ dataset\n",
    "fer_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Ensure the images have 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.485, 0.485], std=[0.229, 0.229, 0.229])\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from vgg11 import VGG11\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import KMNIST\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "\n",
    "from FER_Dataset import FERPlusDataset, fer_transform\n",
    "\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-m\", \"--model\", type=str, required=True,\n",
    "# \thelp=\"path to output trained model\")\n",
    "# ap.add_argument(\"-p\", \"--plot\", type=str, required=True,\n",
    "# \thelp=\"path to output loss/accuracy plot\")\n",
    "# ap.add_argument(\"-lr\", \"--learningRate\", type=float, required=True,\n",
    "# \thelp=\"path to output loss/accuracy plot\")\n",
    "args = {\n",
    "    \"model\": \"output/model.pth\",\n",
    "    \"plot\": \"output/plot.png\",\n",
    "    \"learningRate\": 1e-3\n",
    "}\n",
    "\n",
    "# define training hyperparameters\n",
    "INIT_LR = args[\"learningRate\"]\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
    "\n",
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "\n",
    "# Load the FER+ dataset\n",
    "trainData = FERPlusDataset(csv_file='fer+/fer2013.csv', transform=fer_transform)\n",
    "#train_loader = DataLoader(trainData, batch_size=32, shuffle=True)\n",
    "\n",
    "# calculate the train/validation split\n",
    "print(\"[INFO] generating the train/validation split...\")\n",
    "numTrainSamples = int(len(trainData) * TRAIN_SPLIT)\n",
    "print(numTrainSamples)\n",
    "numValSamples = len(trainData) - numTrainSamples\n",
    "(trainData, valData) = random_split(trainData,\n",
    "\t[numTrainSamples, numValSamples],\n",
    "\tgenerator=torch.Generator().manual_seed(42))\n",
    "\n",
    "\n",
    "# initialize the train, validation, and test data loaders\n",
    "trainDataLoader = DataLoader(trainData, shuffle=True,\n",
    "\tbatch_size=BATCH_SIZE)\n",
    "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
    "\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "valSteps = len(valDataLoader.dataset) // BATCH_SIZE\n",
    "\n",
    "# initialize the VGG model\n",
    "print(\"[INFO] initializing the VGG model...\")\n",
    "model = VGG11().to(device)\n",
    "\n",
    "\n",
    "# initialize a dictionary to store training history\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"train_acc\": [],\n",
    "\t\"val_loss\": [],\n",
    "\t\"val_acc\": []\n",
    "}\n",
    "\n",
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "# initialize our optimizer and loss function\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = nn.CrossEntropyLoss()\n",
    "\n",
    "# loop over our epochs\n",
    "for e in range(0, EPOCHS):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "\n",
    "    # initialize the number of correct predictions in the training\n",
    "    # and validation step\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "\n",
    "    # loop over the training set\n",
    "    for (x, y) in trainDataLoader:\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        \n",
    "        # perform a forward pass and calculate the training loss\n",
    "        pred = model(x)\n",
    "        loss = lossFn(pred, y)\n",
    "        \n",
    "        # zero out the gradients, perform the backpropagation step,\n",
    "        # and update the weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        # add the loss to the total training loss so far and\n",
    "        # calculate the number of correct predictions\n",
    "        totalTrainLoss += loss\n",
    "        trainCorrect += (pred.argmax(1) == y).type(\n",
    "            torch.float).sum().item()\n",
    "        \n",
    "    # switch off autograd for evaluation\n",
    "    with torch.no_grad():\n",
    "        # set the model in evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # loop over the validation set\n",
    "        for (x, y) in valDataLoader:\n",
    "            # send the input to the device\n",
    "            (x, y) = (x.to(device), y.to(device))\n",
    "            \n",
    "            # make the predictions and calculate the validation loss\n",
    "            pred = model(x)\n",
    "            totalValLoss += lossFn(pred, y)\n",
    "            \n",
    "            # calculate the number of correct predictions\n",
    "            valCorrect += (pred.argmax(1) == y).type(\n",
    "                torch.float).sum().item()\n",
    "            \n",
    "    # calculate the average training and validation loss\n",
    "    avgTrainLoss = totalTrainLoss / trainSteps\n",
    "    avgValLoss = totalValLoss / valSteps\n",
    "\n",
    "    # calculate the training and validation accuracy\n",
    "    trainCorrect = trainCorrect / len(trainDataLoader.dataset)\n",
    "    valCorrect = valCorrect / len(valDataLoader.dataset)\n",
    "\n",
    "    # update our training history\n",
    "    H[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "    H[\"train_acc\"].append(trainCorrect)\n",
    "    H[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "    H[\"val_acc\"].append(valCorrect)\n",
    "\n",
    "    # print the model training and validation information\n",
    "    print(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
    "    print(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "        avgTrainLoss, trainCorrect))\n",
    "    print(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(\n",
    "        avgValLoss, valCorrect))\n",
    "\n",
    "    # finish measuring how long training took\n",
    "    endTime = time.time()\n",
    "    print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "        endTime - startTime))\n",
    "    \n",
    "    # # we can now evaluate the network on the test set\n",
    "    # print(\"[INFO] evaluating network...\")\n",
    "\n",
    "    # # turn off autograd for testing evaluation\n",
    "    # with torch.no_grad():\n",
    "    #     # set the model in evaluation mode\n",
    "    #     model.eval()\n",
    "        \n",
    "    #     # initialize a list to store our predictions\n",
    "    #     preds = []\n",
    "\n",
    "    #     # loop over the test set\n",
    "    #     for (x, y) in testDataLoader:\n",
    "    #         # send the input to the device\n",
    "    #         x = x.to(device)\n",
    "\n",
    "    #         # make the predictions and add them to the list\n",
    "    #         pred = model(x)\n",
    "    #         preds.extend(pred.argmax(axis=1).cpu().numpy())\n",
    "\n",
    "    # # generate a classification report\n",
    "    # print(classification_report(testData.targets.cpu().numpy(),\n",
    "    #     np.array(preds), target_names=testData.classes))\n",
    "    \n",
    "    # plot the training loss and accuracy\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "    plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot(H[\"train_acc\"], label=\"train_acc\")\n",
    "    plt.plot(H[\"val_acc\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss/Accuracy\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(args[\"plot\"])\n",
    "\n",
    "    # serialize the model to disk\n",
    "    torch.save(model, args[\"model\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
